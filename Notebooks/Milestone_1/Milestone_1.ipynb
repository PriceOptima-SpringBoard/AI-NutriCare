{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f453acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Admissions...\n",
      "Processing Labs...\n",
      "Processing Vitals...\n",
      "Processing Inputs...\n",
      "Warning: inputevents_mv.csv not found. Meds/Input set to 0.\n",
      "Processing Outputs...\n",
      "Merging Features...\n",
      "\n",
      "SUCCESS!\n",
      "Features: 17\n",
      "Saved to: C:\\AINutriCare\\Data\\Transformed\\processed_mimic_24h_final.csv\n",
      "      hadm_id  hour_bin  Heart Rate  MAP  Respiratory Rate  Temperature  \\\n",
      "0  20044587.0         0         0.0  0.0               0.0          0.0   \n",
      "1  20044587.0         1         0.0  0.0               0.0          0.0   \n",
      "2  20044587.0         2         0.0  0.0               0.0          0.0   \n",
      "3  20044587.0         3         0.0  0.0               0.0          0.0   \n",
      "4  20044587.0         4         0.0  0.0               0.0          0.0   \n",
      "\n",
      "   Glucose  Creatinine  BUN  Sodium  Potassium  Hemoglobin  WBC  Lactate  \\\n",
      "0    108.0         0.0  0.0   142.0        3.6        12.0  0.0      1.4   \n",
      "1    141.0         0.0  0.0   142.0        5.2        10.2  0.0      2.7   \n",
      "2    171.0         0.0  0.0   142.0        5.1         9.5  0.0      1.8   \n",
      "3    171.0         0.0  0.0   142.0        5.1         9.5  0.0      1.8   \n",
      "4    120.0         0.0  0.0   140.0        4.0         8.1  0.0      2.7   \n",
      "\n",
      "   Fluid Balance  Vasopressors  Sedatives  Antibiotics  Insulin  \n",
      "0            0.0             0          0            0        0  \n",
      "1            0.0             0          0            0        0  \n",
      "2            0.0             0          0            0        0  \n",
      "3            0.0             0          0            0        0  \n",
      "4            0.0             0          0            0        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. Configuration & ID Definitions\n",
    "# ==========================================\n",
    "raw_dir = r\"C:\\AINutriCare\\Data\\Raw\"\n",
    "output_dir = r\"C:\\AINutriCare\\Data\\Transformed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def get_raw_path(filename): return os.path.join(raw_dir, filename)\n",
    "\n",
    "# Mapping User List to MIMIC-III Item IDs\n",
    "CONFIG = {\n",
    "    # --- LABS ---\n",
    "    \"Labs\": {\n",
    "        \"Glucose\": [50931, 50809],\n",
    "        \"Creatinine\": [50912],\n",
    "        \"BUN\": [51006],\n",
    "        \"Sodium\": [50983, 50824],\n",
    "        \"Potassium\": [50971, 50822],\n",
    "        \"Hemoglobin\": [51222, 50811],\n",
    "        \"WBC\": [51301, 51300],\n",
    "        \"Lactate\": [50813]\n",
    "    },\n",
    "    # --- VITALS ---\n",
    "    \"Vitals\": {\n",
    "        \"Heart Rate\": [211, 220045],\n",
    "        # MAP IDs (Mean Arterial Pressure)\n",
    "        \"MAP\": [456, 52, 220181, 220052], \n",
    "        \"Respiratory Rate\": [618, 615, 220210, 224690],\n",
    "        \"Temperature\": [223761, 678], # Fahrenheit\n",
    "    },\n",
    "    # --- MEDS (Inputs) ---\n",
    "    \"Inputs\": {\n",
    "        \"Vasopressors\": [221906, 221289, 221662, 222315], # Norepi, Vasopressin...\n",
    "        \"Sedatives\": [222168, 221668, 221744], # Propofol, Midazolam...\n",
    "        \"Antibiotics\": [225798, 225837, 225840, 225842, 225843], # Vancomycin...\n",
    "        \"Insulin\": [223258, 223260, 223262],\n",
    "    }\n",
    "}\n",
    "\n",
    "LAB_IDS = [id for sublist in CONFIG[\"Labs\"].values() for id in sublist]\n",
    "VITAL_IDS = [id for sublist in CONFIG[\"Vitals\"].values() for id in sublist]\n",
    "MED_IDS = [id for sublist in CONFIG[\"Inputs\"].values() for id in sublist]\n",
    "\n",
    "# ==========================================\n",
    "# 2. Helper Function (Time-Series Pivot)\n",
    "# ==========================================\n",
    "def process_time_series(df, time_col, val_col, item_col, id_map, aggregation='mean'):\n",
    "    # Merge with Admissions to get 'Admit Time'\n",
    "    df = pd.merge(df, admissions[['hadm_id', 'admittime']], on='hadm_id', how='inner')\n",
    "    \n",
    "    # Calculate 'Hours Since Admission'\n",
    "    df['hours_in'] = (df[time_col] - df['admittime']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Filter: Keep only Hours 0 to 24\n",
    "    df_24 = df[(df['hours_in'] >= 0) & (df['hours_in'] <= 24)].copy()\n",
    "    df_24['hour_bin'] = np.floor(df_24['hours_in']).astype(int)\n",
    "    \n",
    "    # Map ItemIDs to Labels (e.g., 211 -> \"Heart Rate\")\n",
    "    reverse_map = {}\n",
    "    for label, ids in id_map.items():\n",
    "        for i in ids: reverse_map[i] = label\n",
    "    df_24['feature_label'] = df_24[item_col].map(reverse_map)\n",
    "    \n",
    "    # Pivot: Rows=Patient/Hour, Cols=Feature\n",
    "    pivot = df_24.pivot_table(\n",
    "        index=['hadm_id', 'hour_bin'], \n",
    "        columns='feature_label', \n",
    "        values=val_col, \n",
    "        aggfunc=aggregation\n",
    "    )\n",
    "    return pivot\n",
    "\n",
    "# ==========================================\n",
    "# 3. Main ETL Logic\n",
    "# ==========================================\n",
    "try:\n",
    "    print(\"Loading Admissions...\")\n",
    "    admissions = pd.read_csv(get_raw_path('admissions.csv'), parse_dates=['admittime'])\n",
    "\n",
    "    # --- PROCESS LABS ---\n",
    "    print(\"Processing Labs...\")\n",
    "    labevents = pd.read_csv(get_raw_path('labevents.csv'), parse_dates=['charttime'])\n",
    "    lab_subset = labevents[labevents['itemid'].isin(LAB_IDS)].copy()\n",
    "    lab_hourly = process_time_series(lab_subset, 'charttime', 'valuenum', 'itemid', CONFIG[\"Labs\"], 'mean')\n",
    "\n",
    "    # --- PROCESS VITALS (MAP, HR, etc.) ---\n",
    "    print(\"Processing Vitals...\")\n",
    "    chartevents = pd.read_csv(get_raw_path('chartevents.csv'), parse_dates=['charttime'])\n",
    "    vitals_subset = chartevents[chartevents['itemid'].isin(VITAL_IDS)].copy()\n",
    "    vitals_hourly = process_time_series(vitals_subset, 'charttime', 'valuenum', 'itemid', CONFIG[\"Vitals\"], 'mean')\n",
    "\n",
    "    # --- PROCESS MEDS & FLUID INPUT ---\n",
    "    print(\"Processing Inputs...\")\n",
    "    try:\n",
    "        inputevents = pd.read_csv(get_raw_path('inputevents_mv.csv'), parse_dates=['starttime'])\n",
    "        \n",
    "        # 1. Meds (Binary or Amount)\n",
    "        meds_subset = inputevents[inputevents['itemid'].isin(MED_IDS)].copy()\n",
    "        meds_hourly = process_time_series(meds_subset, 'starttime', 'amount', 'itemid', CONFIG[\"Inputs\"], 'sum')\n",
    "        \n",
    "        # 2. Total Input Volume (for Fluid Balance)\n",
    "        inputevents = pd.merge(inputevents, admissions[['hadm_id', 'admittime']], on='hadm_id', how='inner')\n",
    "        inputevents['hours_in'] = (inputevents['starttime'] - inputevents['admittime']).dt.total_seconds() / 3600\n",
    "        input_24 = inputevents[(inputevents['hours_in'] >= 0) & (inputevents['hours_in'] <= 24)].copy()\n",
    "        input_24['hour_bin'] = np.floor(input_24['hours_in']).astype(int)\n",
    "        \n",
    "        total_input = input_24.pivot_table(\n",
    "            index=['hadm_id', 'hour_bin'], values='amount', aggfunc='sum'\n",
    "        ).rename(columns={'amount': 'Input'})\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: inputevents_mv.csv not found. Meds/Input set to 0.\")\n",
    "        meds_hourly = pd.DataFrame()\n",
    "        total_input = pd.DataFrame()\n",
    "\n",
    "    # --- PROCESS FLUID OUTPUT ---\n",
    "    print(\"Processing Outputs...\")\n",
    "    try:\n",
    "        outputevents = pd.read_csv(get_raw_path('outputevents.csv'), parse_dates=['charttime'])\n",
    "        outputevents = pd.merge(outputevents, admissions[['hadm_id', 'admittime']], on='hadm_id', how='inner')\n",
    "        outputevents['hours_in'] = (outputevents['charttime'] - outputevents['admittime']).dt.total_seconds() / 3600\n",
    "        output_24 = outputevents[(outputevents['hours_in'] >= 0) & (outputevents['hours_in'] <= 24)].copy()\n",
    "        output_24['hour_bin'] = np.floor(output_24['hours_in']).astype(int)\n",
    "        \n",
    "        total_output = output_24.pivot_table(\n",
    "            index=['hadm_id', 'hour_bin'], values='value', aggfunc='sum'\n",
    "        ).rename(columns={'value': 'Output'})\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: outputevents.csv not found. Output set to 0.\")\n",
    "        total_output = pd.DataFrame()\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. Merging & Final Calculations\n",
    "    # ==========================================\n",
    "    print(\"Merging Features...\")\n",
    "    combined_df = pd.concat([lab_hourly, vitals_hourly, meds_hourly, total_input, total_output], axis=1)\n",
    "\n",
    "    # Reindex to ensure every patient has exactly 24 rows\n",
    "    unique_stays = combined_df.index.get_level_values(0).unique()\n",
    "    full_idx = pd.MultiIndex.from_product([unique_stays, range(24)], names=['hadm_id', 'hour_bin'])\n",
    "    combined_df = combined_df.reindex(full_idx)\n",
    "\n",
    "    # Handle Missing 'Input'/'Output' before calculation\n",
    "    if 'Input' not in combined_df.columns: combined_df['Input'] = 0\n",
    "    if 'Output' not in combined_df.columns: combined_df['Output'] = 0\n",
    "    combined_df['Input'] = combined_df['Input'].fillna(0)\n",
    "    combined_df['Output'] = combined_df['Output'].fillna(0)\n",
    "\n",
    "    # --- CALCULATE FLUID BALANCE ---\n",
    "    combined_df['Fluid Balance'] = combined_df['Input'] - combined_df['Output']\n",
    "\n",
    "    # Clean Up: Drop raw Input/Output if you only want Balance (Optional - keeping them doesn't hurt)\n",
    "    # The user asked for \"Fluid Balance\", so we focus on that.\n",
    "\n",
    "    # Impute Missing Values\n",
    "    # Forward Fill (e.g., Creatinine doesn't change every hour)\n",
    "    combined_df = combined_df.groupby('hadm_id').ffill()\n",
    "    \n",
    "    # Fill Meds with 0 (No record = drug not given)\n",
    "    for col in CONFIG[\"Inputs\"].keys():\n",
    "        if col in combined_df.columns: combined_df[col] = combined_df[col].fillna(0)\n",
    "            \n",
    "    # Fill remaining Vitals/Labs with 0 or Mean (using 0 for safety in deep learning, scaler fixes it later)\n",
    "    combined_df = combined_df.fillna(0)\n",
    "\n",
    "    # --- FINAL COLUMN SELECTION ---\n",
    "    # Ensure columns appear exactly as requested\n",
    "    requested_cols = [\n",
    "        \"Heart Rate\", \"MAP\", \"Respiratory Rate\", \"Temperature\", \n",
    "        \"Glucose\", \"Creatinine\", \"BUN\", \"Sodium\", \"Potassium\", \"Hemoglobin\", \"WBC\", \"Lactate\",\n",
    "        \"Fluid Balance\", \n",
    "        \"Vasopressors\", \"Sedatives\", \"Antibiotics\", \"Insulin\"\n",
    "    ]\n",
    "    \n",
    "    # Add missing columns as 0\n",
    "    for col in requested_cols:\n",
    "        if col not in combined_df.columns: combined_df[col] = 0\n",
    "            \n",
    "    final_df = combined_df[requested_cols]\n",
    "    final_df.reset_index(inplace=True)\n",
    "\n",
    "    # Save\n",
    "    out_file = os.path.join(output_dir, 'processed_mimic_24h_final.csv')\n",
    "    final_df.to_csv(out_file, index=False)\n",
    "    \n",
    "    print(\"\\nSUCCESS!\")\n",
    "    print(f\"Features: {len(requested_cols)}\")\n",
    "    print(f\"Saved to: {out_file}\")\n",
    "    print(final_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc67644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading Admissions Data...\n",
      "Admissions Loaded. Total Records: 275\n",
      "          hospital_expire_flag\n",
      "hadm_id                       \n",
      "24181354                     0\n",
      "25926192                     0\n",
      "23983182                     0\n",
      "22942076                     1\n",
      "21606243                     0\n",
      "\n",
      "Step 2: Checking Class Balance...\n",
      "Survived (0): 260\n",
      "Expired  (1): 15\n",
      "Imbalance Ratio: 1:17\n",
      "\n",
      "Step 3: Loading Processed Time-Series Data...\n",
      "Time-Series Shape: (5640, 19)\n",
      "\n",
      "Step 4: Aligning X and y...\n",
      "Dimensions -> Patients: 235, Hours: 24, Features: 17\n",
      "X_final Shape Created: (235, 24, 17)\n",
      "y_final Shape Created: (235,)\n",
      "\n",
      "Step 5: Verification...\n",
      "Patient ID: 20044587.0\n",
      "Label (y): 0 (0=Survive, 1=Die)\n",
      "Data Shape (X): (24, 17)\n",
      "Sample Data (First 3 hours of Heart Rate):\n",
      "[0. 0. 0.]\n",
      "\n",
      "Step 6: Saving .npy Files...\n",
      "SUCCESS: X_final.npy and y_final.npy saved.\n",
      "You are now ready for Milestone 3: Model Training.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Configuration & Imports\n",
    "# ==========================================\n",
    "raw_dir = r\"C:\\AINutriCare\\Data\\Raw\"\n",
    "processed_dir = r\"C:\\AINutriCare\\Data\\Transformed\"\n",
    "\n",
    "def get_raw_path(filename): return os.path.join(raw_dir, filename)\n",
    "def get_proc_path(filename): return os.path.join(processed_dir, filename)\n",
    "\n",
    "# ==========================================\n",
    "# 2-4. Load Admissions & Inspect Labels\n",
    "# ==========================================\n",
    "print(\"Step 1: Loading Admissions Data...\")\n",
    "try:\n",
    "    admissions = pd.read_csv(get_raw_path('admissions.csv'))\n",
    "    \n",
    "    # Keep only what we need: Patient ID and the Target Label (Death Flag)\n",
    "    # hospital_expire_flag: 1 = Died in Hospital, 0 = Survived\n",
    "    admission_labels = admissions[['hadm_id', 'hospital_expire_flag']].set_index('hadm_id')\n",
    "    \n",
    "    print(f\"Admissions Loaded. Total Records: {len(admission_labels)}\")\n",
    "    print(admission_labels.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: admissions.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 5. Check Label Distribution\n",
    "# ==========================================\n",
    "print(\"\\nStep 2: Checking Class Balance...\")\n",
    "counts = admission_labels['hospital_expire_flag'].value_counts()\n",
    "print(f\"Survived (0): {counts.get(0, 0)}\")\n",
    "print(f\"Expired  (1): {counts.get(1, 0)}\")\n",
    "print(f\"Imbalance Ratio: 1:{counts.get(0, 0) // counts.get(1, 1)}\")\n",
    "# Note: ICU data is usually heavily imbalanced (mostly survivors). \n",
    "# We will handle this during training (Milestone 3) using Class Weights.\n",
    "\n",
    "# ==========================================\n",
    "# 6. Load Final Time-Series Dataset\n",
    "# ==========================================\n",
    "print(\"\\nStep 3: Loading Processed Time-Series Data...\")\n",
    "try:\n",
    "    # Load the file generated in the previous step\n",
    "    df = pd.read_csv(get_proc_path('processed_mimic_24h_final.csv'))\n",
    "    print(f\"Time-Series Shape: {df.shape}\")\n",
    "    \n",
    "    # Ensure data is sorted by Patient and Time (Crucial for LSTM)\n",
    "    df = df.sort_values(by=['hadm_id', 'hour_bin'])\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Processed CSV not found. Run the previous data processing step first.\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 7 & 8. Create X (3D Features) and y (Labels)\n",
    "# ==========================================\n",
    "print(\"\\nStep 4: Aligning X and y...\")\n",
    "\n",
    "# Get list of unique patients in our time-series data\n",
    "unique_patients = df['hadm_id'].unique()\n",
    "num_patients = len(unique_patients)\n",
    "num_hours = 24\n",
    "# Drop metadata to count features\n",
    "feature_cols = [c for c in df.columns if c not in ['hadm_id', 'hour_bin', 'index', 'level_0']]\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "print(f\"Dimensions -> Patients: {num_patients}, Hours: {num_hours}, Features: {num_features}\")\n",
    "\n",
    "# --- Construct X (Features) ---\n",
    "# Reshape (Rows) -> (Patients, Time, Features)\n",
    "# We use .values to convert dataframe to numpy array\n",
    "try:\n",
    "    X_final = df[feature_cols].values.reshape(num_patients, num_hours, num_features)\n",
    "    print(f\"X_final Shape Created: {X_final.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error reshaping: {e}\")\n",
    "    print(\"Check if every patient has exactly 24 rows. The previous script should have ensured this.\")\n",
    "    exit()\n",
    "\n",
    "# --- Construct y (Labels) ---\n",
    "# We must ensure y[i] corresponds exactly to X_final[i]\n",
    "y_final = []\n",
    "missing_labels = 0\n",
    "\n",
    "for pid in unique_patients:\n",
    "    try:\n",
    "        # Look up the label in the admissions table\n",
    "        label = admission_labels.loc[pid, 'hospital_expire_flag']\n",
    "        y_final.append(label)\n",
    "    except KeyError:\n",
    "        # Should not happen if data is consistent, but good to handle\n",
    "        print(f\"Warning: Label not found for hadm_id {pid}\")\n",
    "        y_final.append(0) # Assume survival if missing (or exclude)\n",
    "        missing_labels += 1\n",
    "\n",
    "y_final = np.array(y_final)\n",
    "print(f\"y_final Shape Created: {y_final.shape}\")\n",
    "\n",
    "if missing_labels > 0:\n",
    "    print(f\"Warning: {missing_labels} patients were missing labels.\")\n",
    "\n",
    "# ==========================================\n",
    "# 9. Inspect Sample Alignment\n",
    "# ==========================================\n",
    "print(\"\\nStep 5: Verification...\")\n",
    "sample_idx = 0\n",
    "print(f\"Patient ID: {unique_patients[sample_idx]}\")\n",
    "print(f\"Label (y): {y_final[sample_idx]} (0=Survive, 1=Die)\")\n",
    "print(f\"Data Shape (X): {X_final[sample_idx].shape}\")\n",
    "print(\"Sample Data (First 3 hours of Heart Rate):\")\n",
    "# Assuming Heart Rate is the first column (index 0)\n",
    "print(X_final[sample_idx, :3, 0]) \n",
    "\n",
    "# ==========================================\n",
    "# 10. Save Final Datasets\n",
    "# ==========================================\n",
    "print(\"\\nStep 6: Saving .npy Files...\")\n",
    "\n",
    "np.save(get_proc_path('X_final.npy'), X_final)\n",
    "np.save(get_proc_path('y_final.npy'), y_final)\n",
    "\n",
    "print(\"SUCCESS: X_final.npy and y_final.npy saved.\")\n",
    "print(\"You are now ready for Milestone 3: Model Training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
