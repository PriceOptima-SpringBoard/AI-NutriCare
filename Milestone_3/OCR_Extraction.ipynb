{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7aef50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\ainutricare\\nutricare\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\ainutricare\\nutricare\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\ainutricare\\nutricare\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: pdfplumber in c:\\ainutricare\\nutricare\\lib\\site-packages (0.11.9)\n",
      "Requirement already satisfied: pandas in c:\\ainutricare\\nutricare\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pdfplumber) (20251230)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pdfplumber) (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\ainutricare\\nutricare\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ainutricare\\nutricare\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract pdf2image pillow pdfplumber pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c2d2353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing file: C:\\Users\\saipr\\Downloads\\satish-patnaik-report-17-Jan-2026-1768654292841.pdf\n",
      "\n",
      "========================================\n",
      "       EXTRACTION RESULTS       \n",
      "========================================\n",
      "Glucose        : 146 mg/dL\n",
      "HbA1c          : 8.2 %\n",
      "Creatinine     : 8.41 mg/dL\n",
      "Urea           : 18 mg/dL\n",
      "Hemoglobin     : 14.7 g/dL\n",
      "WBC            : 5520 /cmm\n",
      "Cholesterol    : 263 mg/dL\n",
      "Triglycerides  : 293 mg/dL\n",
      "TSH            : 7.415 ¬µIU/mL\n",
      "Vitamin D      : ---\n",
      "Vitamin B12    : ---\n",
      "Age            : 54 Years\n",
      "\n",
      "[SUCCESS] Results saved to 'patient_vitals.json'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION: Set the file path here\n",
    "# ==========================================\n",
    "# Change this path to the specific PDF you want to process right now.\n",
    "PDF_PATH = r\"C:\\Users\\saipr\\Downloads\\satish-patnaik-report-17-Jan-2026-1768654292841.pdf\" \n",
    "\n",
    "# Point to Tesseract (only needed if PDF has no selectable text)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# ==========================================\n",
    "# UNIVERSAL PATTERN MAP\n",
    "# ==========================================\n",
    "# Each key has a LIST of patterns. The script tries them in order.\n",
    "EXTRACTORS = {\n",
    "    \"Glucose\": [\n",
    "        # Format 1: \"Glucose fasting ... 146\" (Satish)\n",
    "        r\"Glucose\\s*[-\\s]*fasting\\b.*?\\s+(\\d{2,3})\",\n",
    "        # Format 2: \"Fasting Blood Sugar ... H 141.0\" (Lyubochka)\n",
    "        r\"Fasting\\s+Blood\\s+Sugar\\b.*?\\s+(?:H|L)?\\s*(\\d{2,3}(?:\\.\\d+)?)\"\n",
    "    ],\n",
    "    \"HbA1c\": [\n",
    "        # Format 1: \"Glyco Hb (HbA1C) ... 8.2\"\n",
    "        r\"Glyco\\s+Hb\\s*\\(HbA1C\\)\\b.*?\\s+(\\d{1,2}\\.\\d{1,2})\",\n",
    "        # Format 2: \"HbA1c ... H 7.10\"\n",
    "        r\"HbA1c\\b.*?\\s+(?:H|L)?\\s*(\\d{1,2}\\.\\d{1,2})\"\n",
    "    ],\n",
    "    \"Creatinine\": [\n",
    "        # Format 1 & 2: \"Creatinine\" or \"Creatinine, Serum\"\n",
    "        r\"Creatinine(?:-serum|,\\s*Serum)?\\b.*?\\s+(\\d{1,2}\\.\\d{1,2})\"\n",
    "    ],\n",
    "    \"Urea\": [\n",
    "        # Format 1: \"UREA* ... 18\"\n",
    "        r\"UREA\\s*\\*?\\s+(\\d{2,3}(?:\\.\\d+)?)\",\n",
    "        # Format 2: \"Urea ... L 18.0\" (Handle L/H flags)\n",
    "        r\"Urea\\b.*?\\s+(?:H|L)?\\s*(\\d{2,3}(?:\\.\\d+)?)\"\n",
    "    ],\n",
    "    \"Hemoglobin\": [\n",
    "        # Format 1 (British spelling): \"Haemoglobin\"\n",
    "        r\"Haemoglobin\\b.*?\\s+(\\d{1,2}\\.\\d{1,2})\",\n",
    "        # Format 2 (American spelling): \"Hemoglobin\"\n",
    "        r\"Hemoglobin\\b.*?\\s+(\\d{1,2}\\.\\d{1,2})\"\n",
    "    ],\n",
    "    \"WBC\": [\n",
    "        # Format 1: \"Total WBC Count\"\n",
    "        r\"Total\\s+WBC\\s+Count\\b.*?\\s+(\\d{4,6})\",\n",
    "        # Format 2: \"WBC Count\"\n",
    "        r\"WBC\\s+Count\\b.*?\\s+(\\d{4,6})\"\n",
    "    ],\n",
    "    \"Cholesterol\": [\n",
    "        # Format 1: \"Cholesterol-Total\"\n",
    "        r\"Cholesterol-Total\\b.*?\\s+(\\d{2,3})\",\n",
    "        # Format 2: \"Cholesterol\" (Negative lookahead avoids matching HDL/LDL lines)\n",
    "        r\"Cholesterol\\b(?!.*HDL).*?\\s+(\\d{2,3}(?:\\.\\d+)?)\"\n",
    "    ],\n",
    "    \"Triglycerides\": [\n",
    "        # Universal: Matches \"Triglyceride\" or \"Triglycerides\" + ignores H/L flags\n",
    "        r\"Triglycerides?\\b.*?\\s+(?:H|L)?\\s*(\\d{2,4}(?:\\.\\d+)?)\"\n",
    "    ],\n",
    "    \"TSH\": [\n",
    "        # Format 1: \"TSH(THYROID...)\"\n",
    "        r\"TSH\\s*\\(THYROID\\s+STATIMULATING\\s+HORMONE\\)\\s*(\\d+\\.\\d+)\",\n",
    "        # Format 2: \"TSH - Thyroid...\"\n",
    "        r\"(?:TSH|Thyroid\\s+Stimulating\\s+Hormone)\\b.*?\\s+(\\d{1,2}\\.\\d{2,4})\"\n",
    "    ],\n",
    "    \"Vitamin D\": [\n",
    "        # Format 2 specific\n",
    "        r\"25\\(OH\\)\\s+Vitamin\\s+D\\b.*?\\s+(\\d{1,3}\\.\\d{2})\"\n",
    "    ],\n",
    "    \"Vitamin B12\": [\n",
    "        # Format 2 specific: Handles \"< 148\" or numbers\n",
    "        r\"Vitamin\\s+B12\\b.*?\\s+(?:H|L|<|>)?\\s*(\\d{2,4})\"\n",
    "    ],\n",
    "    \"Age\": [\n",
    "        # Format 1: \"Age/Gender: 54 years\"\n",
    "        r\"Age\\s*/\\s*Gender\\s*:\\s*(\\d{1,3})\\s*years\",\n",
    "        # Format 2: \"Sex/Age : Male / 41 Y\"\n",
    "        r\"Sex\\s*/\\s*Age\\s*:\\s*\\w+\\s*/\\s*(\\d{1,3})\\s*Y\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "UNIT_MAP = {\n",
    "    \"Glucose\": \"mg/dL\", \"Creatinine\": \"mg/dL\", \"Urea\": \"mg/dL\", \n",
    "    \"Hemoglobin\": \"g/dL\", \"WBC\": \"/cmm\", \"Age\": \"Years\", \n",
    "    \"Cholesterol\": \"mg/dL\", \"Triglycerides\": \"mg/dL\", \"HbA1c\": \"%\", \n",
    "    \"TSH\": \"¬µIU/mL\", \"Vitamin D\": \"ng/mL\", \"Vitamin B12\": \"pg/mL\"\n",
    "}\n",
    "\n",
    "def get_text_from_pdf(pdf_path: str) -> str:\n",
    "    print(f\"[INFO] Processing file: {pdf_path}\")\n",
    "    text_pages = []\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                # x_tolerance=2 helps preserve spaces between columns in tables\n",
    "                text = page.extract_text(x_tolerance=2)\n",
    "                if text:\n",
    "                    text_pages.append(text)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] pdfplumber error: {e}\")\n",
    "\n",
    "    full_text = \"\\n\".join(text_pages)\n",
    "\n",
    "    # Fallback to OCR if text is missing or extremely short\n",
    "    if len(full_text) < 50:\n",
    "        print(\"[INFO] Text not found. Attempting OCR...\")\n",
    "        try:\n",
    "            images = convert_from_path(pdf_path, dpi=300)\n",
    "            ocr_text = []\n",
    "            for img in images:\n",
    "                ocr_text.append(pytesseract.image_to_string(img))\n",
    "            full_text = \"\\n\".join(ocr_text)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] OCR failed: {e}\")\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "def extract_data(text: str) -> Dict[str, Any]:\n",
    "    results = {}\n",
    "    \n",
    "    for param_name, patterns in EXTRACTORS.items():\n",
    "        found_value = None\n",
    "        match_source = None\n",
    "        \n",
    "        # Try every pattern in the list until one works\n",
    "        for pattern in patterns:\n",
    "            # re.DOTALL allows the dot (.) to match newlines if layout is multi-line\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "            if match:\n",
    "                # We assume the actual value is the LAST capture group in the regex\n",
    "                found_value = match.groups()[-1].strip()\n",
    "                match_source = match.group(0).strip()\n",
    "                break # Stop looking for this parameter\n",
    "        \n",
    "        results[param_name] = {\n",
    "            \"value\": found_value,\n",
    "            \"unit\": UNIT_MAP.get(param_name, \"\"),\n",
    "            \"raw_match\": match_source if found_value else \"Not Found\"\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # 1. Extract text from the single file defined in PDF_PATH\n",
    "    raw_text = get_text_from_pdf(PDF_PATH)\n",
    "    \n",
    "    # 2. Extract structured data\n",
    "    data = extract_data(raw_text)\n",
    "    \n",
    "    # 3. Print Results\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"       EXTRACTION RESULTS       \")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for key, info in data.items():\n",
    "        val = info['value']\n",
    "        unit = info['unit']\n",
    "        display_val = f\"{val} {unit}\" if val else \"---\"\n",
    "        print(f\"{key:15}: {display_val}\")\n",
    "\n",
    "    # 4. Save to JSON\n",
    "    out_file = \"patient_vitals.json\"\n",
    "    with open(out_file, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"\\n[SUCCESS] Results saved to '{out_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d7889f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AI Model & Scaler...\n",
      "‚úÖ AI Resources Loaded Successfully.\n",
      "Running LSTM Prediction...\n",
      "\n",
      "Processing AI Clinical Analysis...\n",
      "‚úÖ Success! Analysis saved to: clinical_output.json\n",
      "{\n",
      "  \"patient_metrics\": {\n",
      "    \"mortality_risk\": 0.32739484310150146,\n",
      "    \"glucose\": 146.0,\n",
      "    \"creatinine\": 8.41\n",
      "  },\n",
      "  \"conditions\": [\n",
      "    \"Moderate Clinical Risk\",\n",
      "    \"Diabetes (Type 2 / Hyperglycemia)\",\n",
      "    \"Renal Stress / Kidney Strain\"\n",
      "  ],\n",
      "  \"avoid\": [\n",
      "    \"Fruit juices\",\n",
      "    \"White bread\",\n",
      "    \"Processed sugars\",\n",
      "    \"High-GI foods\",\n",
      "    \"High sodium foods\",\n",
      "    \"Excessive red meat\",\n",
      "    \"Processed deli meats\"\n",
      "  ],\n",
      "  \"recommend\": [\n",
      "    \"Complex carbohydrates\",\n",
      "    \"High fiber foods (>30g/day)\",\n",
      "    \"Leafy greens\",\n",
      "    \"Low-potassium vegetables\",\n",
      "    \"Cauliflower\",\n",
      "    \"Berries\"\n",
      "  ],\n",
      "  \"summary\": \"Patient requires dietary management and monitoring.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. Configuration & Paths\n",
    "# ==========================================\n",
    "# Ensure these paths match your local setup\n",
    "JSON_INPUT = \"patient_vitals.json\"\n",
    "MODEL_PATH = r\"C:\\AINutriCare\\Notebooks\\Milestone_2\\LSTM\\attention_lstm.h5\"\n",
    "SCALER_PATH = r\"C:\\AINutriCare\\Data\\Transformed\\X_final.npy\"\n",
    "\n",
    "# The 17 Features the Model was trained on (Must be in this exact order)\n",
    "MODEL_FEATURES = [\n",
    "    \"Heart Rate\", \"MAP\", \"Respiratory Rate\", \"Temperature\", \n",
    "    \"Glucose\", \"Creatinine\", \"BUN\", \"Sodium\", \"Potassium\", \"Hemoglobin\", \"WBC\", \"Lactate\",\n",
    "    \"Fluid Balance\", \"Vasopressors\", \"Sedatives\", \"Antibiotics\", \"Insulin\"\n",
    "]\n",
    "\n",
    "# Defaults for values NOT in the PDF (Assumes resting/stable state for missing vitals)\n",
    "DEFAULTS = {\n",
    "    'Heart Rate': 75, 'MAP': 90, 'Respiratory Rate': 16, 'Temperature': 98.4,\n",
    "    'Lactate': 1.0, 'Fluid Balance': 0, 'Vasopressors': 0, 'Sedatives': 0, \n",
    "    'Antibiotics': 0, 'Insulin': 0\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. Define Custom Layer (Required to load model)\n",
    "# ==========================================\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class SimpleAttention(Layer):\n",
    "    def __init__(self, units=64, **kwargs):\n",
    "        super(SimpleAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    def get_config(self):\n",
    "        config = super(SimpleAttention, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self.W1 = self.add_weight(name='att_w1', shape=(input_shape[-1], self.units), initializer='glorot_uniform')\n",
    "        self.W2 = self.add_weight(name='att_w2', shape=(self.units, 1), initializer='glorot_uniform')\n",
    "        self.b1 = self.add_weight(name='att_b1', shape=(self.units,), initializer='zeros')\n",
    "        super(SimpleAttention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        h = tf.nn.tanh(tf.matmul(x, self.W1) + self.b1)\n",
    "        e = tf.squeeze(tf.matmul(h, self.W2), -1)\n",
    "        alpha = tf.nn.softmax(e)\n",
    "        context = x * tf.expand_dims(alpha, -1)\n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, alpha\n",
    "\n",
    "# ==========================================\n",
    "# 3. Load Resources\n",
    "# ==========================================\n",
    "def load_ai_resources():\n",
    "    print(\"Loading AI Model & Scaler...\")\n",
    "    try:\n",
    "        # 1. Load Model\n",
    "        if not os.path.exists(MODEL_PATH):\n",
    "            raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}\")\n",
    "        model = load_model(MODEL_PATH, custom_objects={'SimpleAttention': SimpleAttention})\n",
    "        \n",
    "        # 2. Load Scaler Statistics (Mean/Std from Training)\n",
    "        if os.path.exists(SCALER_PATH):\n",
    "            X_ref = np.load(SCALER_PATH)\n",
    "            X_flat = X_ref.reshape(-1, X_ref.shape[2])\n",
    "            means = np.mean(X_flat, axis=0)\n",
    "            stds = np.std(X_flat, axis=0)\n",
    "            stds[stds == 0] = 1.0 # Prevent divide by zero\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Scaler file (X_final.npy) not found. Using raw unscaled values (Results may be inaccurate).\")\n",
    "            means = np.zeros(17)\n",
    "            stds = np.ones(17)\n",
    "            \n",
    "        print(\"‚úÖ AI Resources Loaded Successfully.\")\n",
    "        return model, means, stds\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error Loading AI Resources: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# ==========================================\n",
    "# 4. Data Processing (JSON -> Tensor)\n",
    "# ==========================================\n",
    "def preprocess_patient_data(json_file, means, stds):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # helper to safely get float values\n",
    "    def get_val(key):\n",
    "        item = data.get(key)\n",
    "        if isinstance(item, dict):\n",
    "            val = item.get('value')\n",
    "        else:\n",
    "            val = item\n",
    "            \n",
    "        if val in [None, \"N/A\", \"Not Found\"]: return None\n",
    "        try:\n",
    "            # Clean string like \"H 141.0\" -> 141.0\n",
    "            clean = str(val).replace('H', '').replace('L', '').strip()\n",
    "            return float(clean)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 1. Build Feature Vector (17,)\n",
    "    vector = []\n",
    "    extracted_values = {} # For reporting\n",
    "    \n",
    "    for feature in MODEL_FEATURES:\n",
    "        # Map Model Feature Names to JSON Keys\n",
    "        json_key = feature\n",
    "        if feature == \"Cholesterol\": json_key = \"Cholestrol\" # Handle typo in json if present\n",
    "        \n",
    "        val = get_val(json_key)\n",
    "        \n",
    "        # Fallback Logic\n",
    "        if val is None:\n",
    "            val = DEFAULTS.get(feature, 0)\n",
    "        \n",
    "        # Scaling fixes (e.g. WBC 10570 -> 10.57)\n",
    "        if feature == \"WBC\" and val > 1000:\n",
    "            val = val / 1000.0\n",
    "            \n",
    "        vector.append(val)\n",
    "        extracted_values[feature] = val\n",
    "\n",
    "    # 2. Create Time Series (Repeat static data for 24 hours)\n",
    "    # Shape: (1, 24, 17)\n",
    "    patient_matrix = np.tile(vector, (24, 1))\n",
    "    \n",
    "    # 3. Normalize\n",
    "    normalized_matrix = (patient_matrix - means) / stds\n",
    "    input_tensor = normalized_matrix.reshape(1, 24, 17)\n",
    "    \n",
    "    return input_tensor, extracted_values, data\n",
    "\n",
    "# ==========================================\n",
    "# 5. Diet Logic (Post-Prediction)\n",
    "# ==========================================\n",
    "def generate_clinical_report(risk_score, vitals, raw_json):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" AI CLINICAL ANALYSIS REPORT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # --- 1. Risk Interpretation ---\n",
    "    if risk_score > 0.60:\n",
    "        status = \"HIGH RISK (Critical)\"\n",
    "        action = \"Immediate Metabolic Intervention\"\n",
    "    elif risk_score > 0.30:\n",
    "        status = \"MODERATE RISK\"\n",
    "        action = \"Dietary Management & Monitoring\"\n",
    "    else:\n",
    "        status = \"STABLE\"\n",
    "        action = \"Routine Maintenance\"\n",
    "        \n",
    "    print(f\"\\n[1] MODEL PREDICTION\")\n",
    "    print(f\"    Mortality/ICU Risk: {risk_score:.2%}\")\n",
    "    print(f\"    Clinical Status:    {status}\")\n",
    "    print(f\"    Recommended Action: {action}\")\n",
    "\n",
    "    # --- 2. Key Drivers ---\n",
    "    print(f\"\\n[2] BIOMARKER ANALYSIS\")\n",
    "    \n",
    "    # Check Diabetes\n",
    "    gluc = vitals['Glucose']\n",
    "    hba1c_val = raw_json.get('HbA1c', {}).get('value', 'N/A')\n",
    "    print(f\"    - Glucose: {gluc} mg/dL\", end=\"\")\n",
    "    if gluc > 140: print(\" (HIGH - Driver for Risk)\")\n",
    "    else: print(\" (Normal)\")\n",
    "    \n",
    "    print(f\"    - HbA1c:   {hba1c_val} %\", end=\"\")\n",
    "    try:\n",
    "        if float(str(hba1c_val).replace('H','')) > 6.5: print(\" (DIABETIC RANGE)\")\n",
    "        else: print(\"\")\n",
    "    except: print(\"\")\n",
    "\n",
    "    # Check Renal\n",
    "    creat = vitals['Creatinine']\n",
    "    print(f\"    - Creatinine: {creat} mg/dL\", end=\"\")\n",
    "    if creat > 1.2: print(\" (RENAL STRESS)\")\n",
    "    else: print(\" (Normal)\")\n",
    "\n",
    "    # --- 3. Diet Plan ---\n",
    "    print(f\"\\n[3] AI-GENERATED NUTRITION PLAN\")\n",
    "    \n",
    "    if gluc > 126 or (hba1c_val != 'N/A' and float(str(hba1c_val).replace('H','')) > 6.5):\n",
    "        print(\"    Protocol: DIABETIC / LOW-GLYCEMIC INDEX\")\n",
    "        print(\"    - Carbohydrates: Restricted to 40% of total calories.\")\n",
    "        print(\"    - Focus: Complex carbs only (Fiber > 30g/day).\")\n",
    "        print(\"    - Avoid: Fruit juices, white bread, processed sugars.\")\n",
    "    elif risk_score > 0.5:\n",
    "        print(\"    Protocol: CRITICAL CARE SUPPORT (High Protein)\")\n",
    "        print(\"    - Focus: Preventing muscle wasting (Catabolism).\")\n",
    "    else:\n",
    "        print(\"    Protocol: STANDARD BALANCED DIET\")\n",
    "        print(\"    - Maintain current nutritional intake.\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "def generate_clinical_report(risk_score, vitals, raw_json):\n",
    "    \"\"\"\n",
    "    Analyzes prediction & vitals to create a JSON for the LLM.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing AI Clinical Analysis...\")\n",
    "\n",
    "    # --- 1. Initialize Structure for LLM ---\n",
    "    llm_context = {\n",
    "        \"patient_metrics\": {\n",
    "            \"mortality_risk\": float(risk_score),  # JSON needs native float, not numpy\n",
    "            \"glucose\": float(vitals['Glucose']),\n",
    "            \"creatinine\": float(vitals['Creatinine'])\n",
    "        },\n",
    "        \"conditions\": [],\n",
    "        \"avoid\": [],\n",
    "        \"recommend\": [],\n",
    "        \"summary\": \"\"\n",
    "    }\n",
    "\n",
    "    # --- 2. Risk Interpretation ---\n",
    "    if risk_score > 0.60:\n",
    "        llm_context['conditions'].append(\"Critical Stability Risk\")\n",
    "        llm_context['summary'] = \"Patient is at HIGH RISK. Immediate metabolic intervention required.\"\n",
    "    elif risk_score > 0.30:\n",
    "        llm_context['conditions'].append(\"Moderate Clinical Risk\")\n",
    "        llm_context['summary'] = \"Patient requires dietary management and monitoring.\"\n",
    "    else:\n",
    "        llm_context['summary'] = \"Patient is stable. Routine maintenance diet recommended.\"\n",
    "\n",
    "    # --- 3. Biomarker Analysis (Logic -> Rules) ---\n",
    "    \n",
    "    # Check Diabetes / Glucose\n",
    "    glucose = vitals['Glucose']\n",
    "    hba1c_val = raw_json.get('HbA1c', {}).get('value', 'N/A')\n",
    "    \n",
    "    is_diabetic = False\n",
    "    if glucose > 126:\n",
    "        is_diabetic = True\n",
    "    # Handle H141 type strings if present in raw json\n",
    "    if hba1c_val != 'N/A':\n",
    "        try:\n",
    "            val = float(str(hba1c_val).replace('H','').replace('L',''))\n",
    "            if val > 6.5: is_diabetic = True\n",
    "        except: pass\n",
    "\n",
    "    if is_diabetic:\n",
    "        llm_context['conditions'].append(\"Diabetes (Type 2 / Hyperglycemia)\")\n",
    "        llm_context['avoid'].extend([\"Fruit juices\", \"White bread\", \"Processed sugars\", \"High-GI foods\"])\n",
    "        llm_context['recommend'].extend([\"Complex carbohydrates\", \"High fiber foods (>30g/day)\", \"Leafy greens\"])\n",
    "\n",
    "    # Check Renal (Kidneys)\n",
    "    creatinine = vitals['Creatinine']\n",
    "    if creatinine > 1.2:\n",
    "        llm_context['conditions'].append(\"Renal Stress / Kidney Strain\")\n",
    "        llm_context['avoid'].extend([\"High sodium foods\", \"Excessive red meat\", \"Processed deli meats\"])\n",
    "        llm_context['recommend'].extend([\"Low-potassium vegetables\", \"Cauliflower\", \"Berries\"])\n",
    "\n",
    "    # Check Hypertension (using MAP as proxy if BP not split)\n",
    "    # MAP > 100 often correlates with high BP\n",
    "    if vitals['MAP'] > 100: \n",
    "        llm_context['conditions'].append(\"Hypertension Risk\")\n",
    "        llm_context['avoid'].append(\"Salt/Sodium\")\n",
    "        llm_context['recommend'].append(\"DASH diet principles\")\n",
    "\n",
    "    # If no specific conditions found, add general healthy advice\n",
    "    if not llm_context['conditions']:\n",
    "        llm_context['conditions'].append(\"General Health Maintenance\")\n",
    "        llm_context['recommend'].append(\"Balanced diet with lean proteins and vegetables\")\n",
    "\n",
    "    return llm_context\n",
    "\n",
    "# ==========================================\n",
    "# 6. Main Execution Loop\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load Model\n",
    "    model, means, stds = load_ai_resources()\n",
    "    \n",
    "    if model:\n",
    "        # 2. Process Data\n",
    "        if os.path.exists(JSON_INPUT):\n",
    "            input_tensor, vitals_dict, raw_data = preprocess_patient_data(JSON_INPUT, means, stds)\n",
    "            \n",
    "            # 3. Predict\n",
    "            print(\"Running LSTM Prediction...\")\n",
    "            prediction = model.predict(input_tensor, verbose=0)[0][0]\n",
    "            \n",
    "            # 4. Generate & Save Report\n",
    "            ai_output = generate_clinical_report(prediction, vitals_dict, raw_data)\n",
    "            \n",
    "            # Output Filename\n",
    "            OUTPUT_FILE = \"clinical_output.json\"\n",
    "            \n",
    "            with open(OUTPUT_FILE, 'w') as f:\n",
    "                json.dump(ai_output, f, indent=4)\n",
    "                \n",
    "            print(f\"‚úÖ Success! Analysis saved to: {OUTPUT_FILE}\")\n",
    "            print(json.dumps(ai_output, indent=2)) # Print preview\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå Error: {JSON_INPUT} not found. Run the extraction step first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f8446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Downloading google_genai-1.58.0-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.47.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-genai) (2.32.5)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-genai) (4.15.0)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from google-genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\ainutricare\\nutricare\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\ainutricare\\nutricare\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\ainutricare\\nutricare\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\ainutricare\\nutricare\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\ainutricare\\nutricare\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\ainutricare\\nutricare\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ainutricare\\nutricare\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.6.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\ainutricare\\nutricare\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.6.1)\n",
      "Downloading google_genai-1.58.0-py3-none-any.whl (718 kB)\n",
      "   ---------------------------------------- 0.0/718.4 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 524.3/718.4 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 718.4/718.4 kB 3.0 MB/s  0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: websockets, tenacity, sniffio, distro, google-genai\n",
      "\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   ---------------------------------------- 0/5 [websockets]\n",
      "   -------- ------------------------------- 1/5 [tenacity]\n",
      "   -------- ------------------------------- 1/5 [tenacity]\n",
      "   -------- ------------------------------- 1/5 [tenacity]\n",
      "   ---------------- ----------------------- 2/5 [sniffio]\n",
      "   ------------------------ --------------- 3/5 [distro]\n",
      "   ------------------------ --------------- 3/5 [distro]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   -------------------------------- ------- 4/5 [google-genai]\n",
      "   ---------------------------------------- 5/5 [google-genai]\n",
      "\n",
      "Successfully installed distro-1.9.0 google-genai-1.58.0 sniffio-1.3.1 tenacity-9.1.2 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770378e2",
   "metadata": {},
   "source": [
    "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\n",
    "AIzaSyD_lIMzf-pDJhSOZoEo8o5PtZUik6Yit6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f2081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Food DB...\n",
      "ü§ñ AI is structuring the JSON plan...\n",
      "\n",
      "‚úÖ GENERATED JSON:\n",
      "{\n",
      "  \"day_plan\": {\n",
      "    \"breakfast\": [\n",
      "      {\n",
      "        \"item\": \"Theeyal\",\n",
      "        \"calories\": 155.0,\n",
      "        \"protein\": 14.0,\n",
      "        \"fat\": 31.0,\n",
      "        \"carbs\": 16.0,\n",
      "        \"tags\": [\n",
      "          \"diabetic_friendly\",\n",
      "          \"low_sugar\",\n",
      "          \"high_protein\",\n",
      "          \"renal_safe\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"item\": \"Brown Rice\",\n",
      "        \"calories\": 139.0,\n",
      "        \"protein\": 14.0,\n",
      "        \"fat\": 13.0,\n",
      "        \"carbs\": 22.0,\n",
      "        \"tags\": [\n",
      "          \"diabetic_friendly\",\n",
      "          \"low_sugar\",\n",
      "          \"high_protein\",\n",
      "          \"renal_safe\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"lunch\": [\n",
      "      {\n",
      "        \"item\": \"Keerai kootu\",\n",
      "        \"calories\": 278.0,\n",
      "        \"protein\": 8.0,\n",
      "        \"fat\": 37.0,\n",
      "        \"carbs\": 11.0,\n",
      "        \"tags\": [\n",
      "          \"diabetic_friendly\",\n",
      "          \"low_sugar\",\n",
      "          \"renal_safe\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"dinner\": [\n",
      "      {\n",
      "        \"item\": \"Vindaloo\",\n",
      "        \"calories\": 220.0,\n",
      "        \"protein\": 11.0,\n",
      "        \"fat\": 30.0,\n",
      "        \"carbs\": 10.0,\n",
      "        \"tags\": [\n",
      "          \"diabetic_friendly\",\n",
      "          \"low_sugar\",\n",
      "          \"high_protein\",\n",
      "          \"renal_safe\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"snacks\": [\n",
      "      {\n",
      "        \"item\": \"Paruppu sadam\",\n",
      "        \"calories\": 41.0,\n",
      "        \"protein\": 9.0,\n",
      "        \"fat\": 15.0,\n",
      "        \"carbs\": 12.0,\n",
      "        \"tags\": [\n",
      "          \"diabetic_friendly\",\n",
      "          \"low_sugar\",\n",
      "          \"renal_safe\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"item\": \"Chicken Tikka masala\",\n",
      "        \"calories\": 59.0,\n",
      "        \"protein\": 9.0,\n",
      "        \"fat\": 11.0,\n",
      "        \"carbs\": 11.0,\n",
      "        \"tags\": [\n",
      "          \"diabetic_friendly\",\n",
      "          \"low_sugar\",\n",
      "          \"renal_safe\"\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"total_nutrition\": {\n",
      "    \"calories\": 892.0,\n",
      "    \"protein\": 66.0,\n",
      "    \"fat\": 137.0,\n",
      "    \"carbs\": 83.0\n",
      "  },\n",
      "  \"medical_reasoning\": \"This meal plan for Rajesh Kumar focuses on dietary management and monitoring by selecting items that are consistently tagged as diabetic-friendly, low in sugar, and renal-safe. The plan incorporates high-protein options to support overall health and satiety, while managing carbohydrate and fat intake. The selected foods aim to provide a balanced nutritional profile within the constraints of the provided candidate list and medical tags.\"\n",
      "}\n",
      "\n",
      "Saved to 'final_structured_diet.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION (GOOGLE GEMINI)\n",
    "# ==========================================\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyD_lIMzf-pDJhSOZoEo8o5PtZUik6Yit6c\"  # or set env var GEMINI_API_KEY\n",
    "MODEL_ID = \"gemini-2.5-flash\"  # choose your Gemini model\n",
    "\n",
    "# File Paths\n",
    "CLINICAL_INPUT = \"clinical_output.json\"\n",
    "FOOD_KB_FILE = \"diet_kb.json\"\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. AUTO-TAGGING & FILTERING SYSTEM\n",
    "# ==========================================\n",
    "def load_and_tag_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads diet_kb.json and adds medical tags based on macros.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        return pd.DataFrame()  # Return empty if missing\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # --- AUTO-TAGGING LOGIC ---\n",
    "    def get_tags(row):\n",
    "        tags = []\n",
    "        # Diabetic Friendly: Low Carb (<30g) OR Low Sugar (ingredients check)\n",
    "        if row[\"Carbohydrate (g)\"] < 30 and \"sugar\" not in str(row[\"ingredients\"]).lower():\n",
    "            tags.append(\"diabetic_friendly\")\n",
    "            tags.append(\"low_sugar\")\n",
    "\n",
    "        # High Protein: > 10g\n",
    "        if row[\"Protein (g)\"] > 10:\n",
    "            tags.append(\"high_protein\")\n",
    "\n",
    "        # Low Fat: < 8g\n",
    "        if row[\"Total Fat (g)\"] < 8:\n",
    "            tags.append(\"low_fat\")\n",
    "\n",
    "        # Renal Safe (Simplified): Moderate Protein (5‚Äì15g)\n",
    "        if 5 < row[\"Protein (g)\"] < 15:\n",
    "            tags.append(\"renal_safe\")\n",
    "\n",
    "        return tags\n",
    "\n",
    "    df[\"medical_tags\"] = df.apply(get_tags, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_smart_candidates(df, clinical_insights):\n",
    "    \"\"\"\n",
    "    Filters the tagged dataframe to find the best candidates for the patient.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return {}\n",
    "\n",
    "    # 1. Parse Constraints\n",
    "    conditions = \" \".join(clinical_insights.get(\"conditions\", [])).lower()\n",
    "    avoid = \" \".join(clinical_insights.get(\"avoid\", [])).lower()\n",
    "\n",
    "    # 2. Apply Filters\n",
    "    candidates = df.copy()\n",
    "\n",
    "    # DIABETES FILTER\n",
    "    if \"diabetes\" in conditions or \"sugar\" in avoid:\n",
    "        candidates = candidates[candidates[\"medical_tags\"].apply(lambda x: \"diabetic_friendly\" in x)]\n",
    "\n",
    "    # RENAL FILTER\n",
    "    if \"renal\" in conditions or \"kidney\" in conditions:\n",
    "        candidates = candidates[candidates[\"medical_tags\"].apply(lambda x: \"renal_safe\" in x)]\n",
    "\n",
    "    # 3. Categorize\n",
    "    breakfast_keywords = \"idli|dosa|upma|poha|paratha|oats|porridge\"\n",
    "    breakfast_df = candidates[candidates[\"name\"].str.contains(breakfast_keywords, case=False, na=False)]\n",
    "    if len(breakfast_df) < 2:\n",
    "        breakfast_df = candidates.sample(n=min(5, len(candidates)))\n",
    "\n",
    "    # Lunch/Dinner: high calorie mains\n",
    "    mains_df = candidates[candidates[\"Energy (kcal)\"] > 150]\n",
    "\n",
    "    # Snacks: low calorie\n",
    "    snacks_df = candidates[candidates[\"Energy (kcal)\"] < 150]\n",
    "\n",
    "    def serialize(sub_df, count=5):\n",
    "        return sub_df.sample(n=min(count, len(sub_df))).to_dict(orient=\"records\")\n",
    "\n",
    "    return {\n",
    "        \"breakfast\": serialize(breakfast_df),\n",
    "        \"lunch\": serialize(mains_df),\n",
    "        \"dinner\": serialize(mains_df),\n",
    "        \"snacks\": serialize(snacks_df),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. LLM GENERATOR (Structure Enforcer ‚Äì GEMINI)\n",
    "# ==========================================\n",
    "def generate_structured_plan(patient_profile, clinical_data, food_candidates):\n",
    "    summary = clinical_data.get(\"summary\", \"Healthy Diet\")\n",
    "    options_preview = json.dumps(food_candidates, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI Clinical Dietitian.\n",
    "\n",
    "    PATIENT: {patient_profile['name']}\n",
    "    CONDITION: {summary}\n",
    "\n",
    "    TASK:\n",
    "    Select items from the PROVIDED CANDIDATE LIST below to create a 1-day meal plan.\n",
    "    You must output the result in STRICT JSON format matching the user's required schema.\n",
    "\n",
    "    CANDIDATE FOODS (Pick from these):\n",
    "    {options_preview}\n",
    "\n",
    "    REQUIRED OUTPUT FORMAT (JSON):\n",
    "    {{\n",
    "      \"day_plan\": {{\n",
    "          \"breakfast\": [\n",
    "              {{ \"item\": \"Name\", \"calories\": 100, \"protein\": 5, \"fat\": 2, \"carbs\": 10, \"tags\": [\"tag1\", \"tag2\"] }}\n",
    "          ],\n",
    "          \"lunch\": [],\n",
    "          \"dinner\": [],\n",
    "          \"snacks\": []\n",
    "      }},\n",
    "      \"total_nutrition\": {{\n",
    "          \"calories\": 0,\n",
    "          \"protein\": 0,\n",
    "          \"carbs\": 0,\n",
    "          \"fat\": 0\n",
    "      }},\n",
    "      \"medical_reasoning\": \"Brief explanation...\"\n",
    "    }}\n",
    "\n",
    "    RULES:\n",
    "    1. Use the EXACT nutritional values from the candidate list. Do not invent numbers.\n",
    "    2. Include the 'medical_tags' provided in the candidate list.\n",
    "    3. Calculate the 'total_nutrition' sum correctly.\n",
    "    4. Output JSON ONLY. No text before or after.\n",
    "    \"\"\"\n",
    "\n",
    "    # JSON schema ‚Äì fully specified for Gemini\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"day_plan\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"breakfast\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"item\": {\"type\": \"string\"},\n",
    "                                \"calories\": {\"type\": \"number\"},\n",
    "                                \"protein\": {\"type\": \"number\"},\n",
    "                                \"fat\": {\"type\": \"number\"},\n",
    "                                \"carbs\": {\"type\": \"number\"},\n",
    "                                \"tags\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"},\n",
    "                                },\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"item\",\n",
    "                                \"calories\",\n",
    "                                \"protein\",\n",
    "                                \"fat\",\n",
    "                                \"carbs\",\n",
    "                                \"tags\",\n",
    "                            ],\n",
    "                        },\n",
    "                    },\n",
    "                    \"lunch\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"item\": {\"type\": \"string\"},\n",
    "                                \"calories\": {\"type\": \"number\"},\n",
    "                                \"protein\": {\"type\": \"number\"},\n",
    "                                \"fat\": {\"type\": \"number\"},\n",
    "                                \"carbs\": {\"type\": \"number\"},\n",
    "                                \"tags\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"},\n",
    "                                },\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"item\",\n",
    "                                \"calories\",\n",
    "                                \"protein\",\n",
    "                                \"fat\",\n",
    "                                \"carbs\",\n",
    "                                \"tags\",\n",
    "                            ],\n",
    "                        },\n",
    "                    },\n",
    "                    \"dinner\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"item\": {\"type\": \"string\"},\n",
    "                                \"calories\": {\"type\": \"number\"},\n",
    "                                \"protein\": {\"type\": \"number\"},\n",
    "                                \"fat\": {\"type\": \"number\"},\n",
    "                                \"carbs\": {\"type\": \"number\"},\n",
    "                                \"tags\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"},\n",
    "                                },\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"item\",\n",
    "                                \"calories\",\n",
    "                                \"protein\",\n",
    "                                \"fat\",\n",
    "                                \"carbs\",\n",
    "                                \"tags\",\n",
    "                            ],\n",
    "                        },\n",
    "                    },\n",
    "                    \"snacks\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"item\": {\"type\": \"string\"},\n",
    "                                \"calories\": {\"type\": \"number\"},\n",
    "                                \"protein\": {\"type\": \"number\"},\n",
    "                                \"fat\": {\"type\": \"number\"},\n",
    "                                \"carbs\": {\"type\": \"number\"},\n",
    "                                \"tags\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"},\n",
    "                                },\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"item\",\n",
    "                                \"calories\",\n",
    "                                \"protein\",\n",
    "                                \"fat\",\n",
    "                                \"carbs\",\n",
    "                                \"tags\",\n",
    "                            ],\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"breakfast\", \"lunch\", \"dinner\", \"snacks\"],\n",
    "            },\n",
    "            \"total_nutrition\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"calories\": {\"type\": \"number\"},\n",
    "                    \"protein\": {\"type\": \"number\"},\n",
    "                    \"fat\": {\"type\": \"number\"},\n",
    "                    \"carbs\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"calories\", \"protein\", \"fat\", \"carbs\"],\n",
    "            },\n",
    "            \"medical_reasoning\": {\"type\": \"string\"},\n",
    "        },\n",
    "        \"required\": [\"day_plan\", \"total_nutrition\", \"medical_reasoning\"],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"ü§ñ AI is structuring the JSON plan...\")\n",
    "        resp = client.models.generate_content(\n",
    "            model=MODEL_ID,\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=schema,\n",
    "                temperature=0.1,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # In JSON mode, resp.parsed is already a Python dict\n",
    "        if hasattr(resp, \"parsed\") and resp.parsed is not None:\n",
    "            return resp.parsed\n",
    "\n",
    "        raw_text = resp.text.strip()\n",
    "        return json.loads(raw_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        raw_text = \"\"\n",
    "        try:\n",
    "            raw_text = resp.text  # may exist if request reached the model\n",
    "        except:\n",
    "            pass\n",
    "        return {\"error\": str(e), \"raw_output\": raw_text}\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. ROUNDING HELPER\n",
    "# ==========================================\n",
    "def round_plan(plan, ndigits=0):\n",
    "    for meal in [\"breakfast\", \"lunch\", \"dinner\", \"snacks\"]:\n",
    "        for dish in plan.get(\"day_plan\", {}).get(meal, []):\n",
    "            for key in [\"calories\", \"protein\", \"fat\", \"carbs\"]:\n",
    "                val = dish.get(key)\n",
    "                if isinstance(val, (int, float)):\n",
    "                    dish[key] = round(val, ndigits)\n",
    "\n",
    "    tn = plan.get(\"total_nutrition\", {})\n",
    "    for key in [\"calories\", \"protein\", \"fat\", \"carbs\"]:\n",
    "        val = tn.get(key)\n",
    "        if isinstance(val, (int, float)):\n",
    "            tn[key] = round(val, ndigits)\n",
    "    return plan\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Loading Food DB...\")\n",
    "    df = load_and_tag_data(FOOD_KB_FILE)\n",
    "\n",
    "    # Clinical insights\n",
    "    if os.path.exists(CLINICAL_INPUT):\n",
    "        with open(CLINICAL_INPUT, \"r\") as f:\n",
    "            clinical_insights = json.load(f)\n",
    "    else:\n",
    "        clinical_insights = {\n",
    "            \"conditions\": [\"Diabetes\"],\n",
    "            \"summary\": \"Patient requires low-sugar, low-carb diet.\",\n",
    "        }\n",
    "\n",
    "    candidates = get_smart_candidates(df, clinical_insights)\n",
    "\n",
    "    patient = {\"name\": \"Rajesh Kumar\", \"age\": 45}\n",
    "    final_json = generate_structured_plan(patient, clinical_insights, candidates)\n",
    "    final_json = round_plan(final_json, ndigits=0)\n",
    "\n",
    "    if \"error\" not in final_json:\n",
    "        print(\"\\n‚úÖ GENERATED JSON:\")\n",
    "        print(json.dumps(final_json, indent=2))\n",
    "\n",
    "        with open(\"final_structured_diet.json\", \"w\") as f:\n",
    "            json.dump(final_json, f, indent=2)\n",
    "            print(\"\\nSaved to 'final_structured_diet.json'\")\n",
    "    else:\n",
    "        print(\"‚ùå Error:\", final_json[\"error\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nutricare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
