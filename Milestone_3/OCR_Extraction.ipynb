{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7aef50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\ainutricare\\nutricare\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\ainutricare\\nutricare\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\ainutricare\\nutricare\\lib\\site-packages (12.0.0)\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: pandas in c:\\ainutricare\\nutricare\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Collecting pdfminer.six==20251230 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-5.3.0-py3-none-win_amd64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20251230->pdfplumber)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\ainutricare\\nutricare\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber)\n",
      "  Using cached cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ainutricare\\nutricare\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.6 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/6.6 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.4/6.6 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.0/6.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 4.0 MB/s  0:00:01\n",
      "Downloading cryptography-46.0.3-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.8/3.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.6/3.5 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.4/3.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 3.9 MB/s  0:00:00\n",
      "Using cached cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)\n",
      "Downloading pypdfium2-5.3.0-py3-none-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.0/3.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.6/3.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 4.1 MB/s  0:00:00\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------------- -------------------------- 2/6 [cffi]\n",
      "   ------------- -------------------------- 2/6 [cffi]\n",
      "   ------------- -------------------------- 2/6 [cffi]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   ---------------------------------------- 6/6 [pdfplumber]\n",
      "\n",
      "Successfully installed cffi-2.0.0 cryptography-46.0.3 pdfminer.six-20251230 pdfplumber-0.11.9 pycparser-2.23 pypdfium2-5.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract pdf2image pillow pdfplumber pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989fef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting text from: C:\\AINutriCare\\Data\\Raw\\Reports\\REPORT.pdf\n",
      "\n",
      "=== Extracted Parameters ===\n",
      "Glucose     : 157.07 mg/dL\n",
      "Insulin     : None µIU/mL\n",
      "Creatinine  : 0.83 mg/dL\n",
      "Urea (BUN)  : None mg/dL\n",
      "Sodium      : 143.00 mmol/L\n",
      "Potassium   : 4.90 mmol/L\n",
      "Hemoglobin  : 14.5 g/dL\n",
      "WBC         : 10570 /cmm\n",
      "Lactate     : None mmol/L\n",
      "pH          : 6.0 \n",
      "Age         : 41 years\n",
      "Gender      : Male \n",
      "Cholestrol  : 189.0 mg/dL\n",
      "[INFO] Saved extracted parameters to: extracted_parameters.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "def extract_medical_parameters(pdf_path):\n",
    "    # Dictionary to store results\n",
    "    extracted_data = {\n",
    "        \"Glucose\": None,\n",
    "        \"Insulin\": \"Not Found\",\n",
    "        \"Creatinine\": None,\n",
    "        \"Urea\": None,\n",
    "        \"BUN\": None,\n",
    "        \"Sodium\": None,\n",
    "        \"Potassium\": None,\n",
    "        \"Hemoglobin\": None,\n",
    "        \"WBC\": None,\n",
    "        \"Lactate\": \"Not Found\",\n",
    "        \"pH\": None,\n",
    "        \"Age\": None,\n",
    "        \"Gender\": None,\n",
    "        \"Cholesterol\": None\n",
    "    }\n",
    "\n",
    "    # Open the PDF\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        # Combine text from all pages to ensure we catch everything\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    # --- REGEX PATTERNS ---\n",
    "    # These patterns are tuned to the specific layout of your provided report\n",
    "    \n",
    "    # 1. Demographics (Sex/Age : Male / 41 Y)\n",
    "    age_gender_match = re.search(r\"Sex/Age\\s*:\\s*(Male|Female)\\s*/\\s*(\\d+)\\s*Y\", full_text, re.IGNORECASE)\n",
    "    if age_gender_match:\n",
    "        extracted_data[\"Gender\"] = age_gender_match.group(1)\n",
    "        extracted_data[\"Age\"] = age_gender_match.group(2)\n",
    "\n",
    "    # 2. Hemoglobin (Test Hemoglobin ... Result 14.5)\n",
    "    hb_match = re.search(r\"Test\\s*Hemoglobin.*?Result\\s*(\\d+\\.?\\d*)\", full_text, re.DOTALL)\n",
    "    if hb_match:\n",
    "        extracted_data[\"Hemoglobin\"] = hb_match.group(1)\n",
    "\n",
    "    # 3. WBC (WBC Count ... 10570)\n",
    "    wbc_match = re.search(r\"WBC\\s*Count\\s*(\\d+)\", full_text)\n",
    "    if wbc_match:\n",
    "        extracted_data[\"WBC\"] = wbc_match.group(1)\n",
    "\n",
    "    # 4. Glucose (Fasting Blood Sugar ... 141.0)\n",
    "    # Note: Using DOTALL to handle potential line breaks between name and result\n",
    "    glucose_match = re.search(r\"Fasting\\s*Blood\\s*Sugar.*?(\\d+\\.?\\d*)\", full_text, re.DOTALL)\n",
    "    if glucose_match:\n",
    "        extracted_data[\"Glucose\"] = glucose_match.group(1)\n",
    "\n",
    "    # 5. Cholesterol (Cholesterol ... 189.0)\n",
    "    chol_match = re.search(r\"Cholesterol\\s+Cholesterol.*?(\\d{2,3}\\.?\\d*)\", full_text, re.DOTALL)\n",
    "    if chol_match:\n",
    "        extracted_data[\"Cholesterol\"] = chol_match.group(1)\n",
    "\n",
    "    # 6. Kidney Profile (Creatinine, Urea, BUN)\n",
    "    creat_match = re.search(r\"Creatinine,\\s*Serum\\s*(\\d+\\.?\\d*)\", full_text)\n",
    "    if creat_match:\n",
    "        extracted_data[\"Creatinine\"] = creat_match.group(1)\n",
    "\n",
    "    # Urea (looking for the specific value 18.0 format in report)\n",
    "    urea_match = re.search(r\"Urea\\s+L?\\s*(\\d+\\.?\\d*)\", full_text)\n",
    "    if urea_match:\n",
    "        extracted_data[\"Urea\"] = urea_match.group(1)\n",
    "\n",
    "    # BUN (Blood Urea Nitrogen)\n",
    "    bun_match = re.search(r\"Blood\\s*Urea\\s*Nitrogen\\s+L?\\s*(\\d+\\.?\\d*)\", full_text)\n",
    "    if bun_match:\n",
    "        extracted_data[\"BUN\"] = bun_match.group(1)\n",
    "\n",
    "    # 7. Electrolytes (Sodium, Potassium)\n",
    "    na_match = re.search(r\"Sodium\\s*\\(Na\\+\\).*?(\\d{3}\\.?\\d*)\", full_text, re.DOTALL)\n",
    "    if na_match:\n",
    "        extracted_data[\"Sodium\"] = na_match.group(1)\n",
    "\n",
    "    k_match = re.search(r\"Potassium\\s*\\(K\\+\\).*?(\\d\\.\\d+)\", full_text, re.DOTALL)\n",
    "    if k_match:\n",
    "        extracted_data[\"Potassium\"] = k_match.group(1)\n",
    "\n",
    "    # 8. pH (Urine pH found in report)\n",
    "    ph_match = re.search(r\"PH\\s+Double\\s*indicator\\s*(\\d+\\.?\\d*)\", full_text)\n",
    "    if ph_match:\n",
    "        extracted_data[\"pH\"] = ph_match.group(1)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# --- EXECUTION ---\n",
    "file_path = 'C:\\AINutriCare\\Data\\Raw\\Reports\\REPORT.pdf' # Ensure this matches your file name\n",
    "results = extract_medical_parameters(file_path)\n",
    "\n",
    "print(\"--- Extracted Medical Parameters ---\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7889f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Resources Loaded.\n",
      "\n",
      "============================================================\n",
      " AUTOMATED AI CLINICAL ANALYSIS\n",
      "============================================================\n",
      "Patient Name: Unknown\n",
      "Data Source:  patient_vitals.json\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000014994E3F240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000014994E3F240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] AI RISK PREDICTION\n",
      "    Score: 44.03% | Status: MODERATE RISK\n",
      "\n",
      "[2] KEY DRIVERS (Extracted)\n",
      "    - Glucose: 141.0\n",
      "    - Creatinine: 0.83\n",
      "    - BUN: 8.41\n",
      "    - Potassium: 4.9\n",
      "    - Hemoglobin: 14.5\n",
      "\n",
      "[3] PERSONALIZED DIET PLAN\n",
      "    ✅ DIABETIC DIET: Low Glycemic Index.\n",
      "       - Target: <45g Carbs per meal. Avoid simple sugars.\n",
      "       - Rationale: HbA1c is 25.0% (Target <6.5%)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. Setup & Configuration\n",
    "# ==========================================\n",
    "# Path to the extracted data from the previous step\n",
    "JSON_INPUT = \"patient_vitals.json\" \n",
    "MODEL_PATH = r\"C:\\AINutriCare\\Notebooks\\Milestone_2\\LSTM\\attention_lstm.h5\"\n",
    "SCALER_PATH = r\"C:\\AINutriCare\\Data\\Transformed\\X_final.npy\"\n",
    "\n",
    "MODEL_FEATURES = [\n",
    "    \"Heart Rate\", \"MAP\", \"Respiratory Rate\", \"Temperature\", \n",
    "    \"Glucose\", \"Creatinine\", \"BUN\", \"Sodium\", \"Potassium\", \"Hemoglobin\", \"WBC\", \"Lactate\",\n",
    "    \"Fluid Balance\", \"Vasopressors\", \"Sedatives\", \"Antibiotics\", \"Insulin\"\n",
    "]\n",
    "\n",
    "# Defaults for missing vitals (Outpatient assumption)\n",
    "DEFAULTS = {\n",
    "    'Heart Rate': 75, 'MAP': 90, 'Respiratory Rate': 16, 'Temperature': 98.4,\n",
    "    'Lactate': 1.0, 'Fluid Balance': 0, 'Vasopressors': 0, 'Sedatives': 0, \n",
    "    'Antibiotics': 0, 'Insulin': 0\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. Model Resources (Same as before)\n",
    "# ==========================================\n",
    "class SimpleAttention(Layer):\n",
    "    def __init__(self, units=64, **kwargs):\n",
    "        super(SimpleAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    def get_config(self):\n",
    "        config = super(SimpleAttention, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self.W1 = self.add_weight(name='att_w1', shape=(input_shape[-1], self.units), initializer='glorot_uniform')\n",
    "        self.W2 = self.add_weight(name='att_w2', shape=(self.units, 1), initializer='glorot_uniform')\n",
    "        self.b1 = self.add_weight(name='att_b1', shape=(self.units,), initializer='zeros')\n",
    "        super(SimpleAttention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        h = tf.nn.tanh(tf.matmul(x, self.W1) + self.b1)\n",
    "        e = tf.squeeze(tf.matmul(h, self.W2), -1)\n",
    "        alpha = tf.nn.softmax(e)\n",
    "        context = x * tf.expand_dims(alpha, -1)\n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, alpha\n",
    "\n",
    "# Load Model\n",
    "try:\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        model = load_model(MODEL_PATH, custom_objects={'SimpleAttention': SimpleAttention})\n",
    "        X_ref = np.load(SCALER_PATH)\n",
    "        X_flat = X_ref.reshape(-1, X_ref.shape[2])\n",
    "        means = np.mean(X_flat, axis=0)\n",
    "        stds = np.std(X_flat, axis=0)\n",
    "        stds[stds == 0] = 1.0\n",
    "        print(\"✅ Model Resources Loaded.\")\n",
    "    else:\n",
    "        # Fallback for testing if files aren't present\n",
    "        print(\"⚠️ Model files not found. Using Mock Logic for demonstration.\")\n",
    "        model = None\n",
    "        means = np.zeros(17)\n",
    "        stds = np.ones(17)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 3. Data Mapper (JSON -> Model Input)\n",
    "# ==========================================\n",
    "def map_patient_data(json_data):\n",
    "    \"\"\"\n",
    "    Converts the JSON report keys into the 17-feature vector for the AI.\n",
    "    \"\"\"\n",
    "    def clean_val(key):\n",
    "        val = json_data.get(key, \"N/A\")\n",
    "        if val == \"N/A\" or val == \"Not Found\": return None\n",
    "        # Clean string: Remove 'H', 'L', units, etc.\n",
    "        clean = str(val).replace('H', '').replace('L', '').replace('<', '').replace('>', '').replace('%', '').strip()\n",
    "        try:\n",
    "            return float(clean)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # Mapping: Model Feature Name -> Report JSON Key\n",
    "    mapping = {\n",
    "        \"Glucose\": \"Fasting Blood Sugar\", \n",
    "        \"Creatinine\": \"Creatinine\",\n",
    "        \"BUN\": \"BUN\",\n",
    "        \"Sodium\": \"Sodium\",\n",
    "        \"Potassium\": \"Potassium\",\n",
    "        \"Hemoglobin\": \"Hemoglobin\",\n",
    "        \"WBC\": \"WBC\",\n",
    "        \"Platelets\": \"Platelets\"\n",
    "    }\n",
    "\n",
    "    patient_vector = []\n",
    "    report_vals = {}\n",
    "\n",
    "    for feature in MODEL_FEATURES:\n",
    "        report_key = mapping.get(feature)\n",
    "        value = clean_val(report_key)\n",
    "        \n",
    "        # Special Logic: WBC Scaling (Model expects 10.5, Report has 10570)\n",
    "        if feature == \"WBC\" and value and value > 1000:\n",
    "            value = value / 1000.0\n",
    "            \n",
    "        if value is not None:\n",
    "            final_val = value\n",
    "            report_vals[feature] = final_val\n",
    "        else:\n",
    "            final_val = DEFAULTS.get(feature, 0)\n",
    "            \n",
    "        patient_vector.append(final_val)\n",
    "\n",
    "    return np.array(patient_vector), report_vals\n",
    "\n",
    "# ==========================================\n",
    "# 4. Prediction & Diet Logic\n",
    "# ==========================================\n",
    "def predict_risk(patient_vector):\n",
    "    # Simulate 24h trajectory (Static Profile)\n",
    "    trajectory = np.tile(patient_vector, (24, 1)) \n",
    "    scaled = (trajectory - means) / stds\n",
    "    input_tensor = scaled.reshape(1, 24, 17)\n",
    "    \n",
    "    if model:\n",
    "        prob = model.predict(input_tensor, verbose=0)[0][0]\n",
    "    else:\n",
    "        # Mock logic if model file missing\n",
    "        gluc = patient_vector[MODEL_FEATURES.index(\"Glucose\")]\n",
    "        prob = 0.85 if gluc > 140 else 0.20\n",
    "        \n",
    "    return prob\n",
    "\n",
    "def generate_diet(prob, vals, full_json):\n",
    "    plans = []\n",
    "    \n",
    "    # AI Score Rule\n",
    "    if prob > 0.6: status = \"HIGH RISK (Metabolic)\"\n",
    "    elif prob > 0.4: status = \"MODERATE RISK\"\n",
    "    else: status = \"STABLE\"\n",
    "\n",
    "    # Specific Lab Rules\n",
    "    # 1. Diabetes\n",
    "    gluc = vals.get(\"Glucose\", 0)\n",
    "    hba1c = full_json.get(\"HbA1c\", \"0\").replace('H','').strip()\n",
    "    try: hba1c = float(hba1c)\n",
    "    except: hba1c = 0\n",
    "    \n",
    "    if gluc > 126 or hba1c > 6.5:\n",
    "        plans.append(\"✅ DIABETIC DIET: Low Glycemic Index.\")\n",
    "        plans.append(\"   - Target: <45g Carbs per meal. Avoid simple sugars.\")\n",
    "        plans.append(\"   - Rationale: HbA1c is \" + str(hba1c) + \"% (Target <6.5%)\")\n",
    "\n",
    "    # 2. Cholesterol\n",
    "    chol_str = full_json.get(\"Total Cholesterol\", \"0\").replace('H','').strip()\n",
    "    try: chol = float(chol_str)\n",
    "    except: chol = 0\n",
    "    if chol > 200:\n",
    "        plans.append(\"✅ CARDIAC DIET: Low Saturated Fat (<7% of calories).\")\n",
    "    \n",
    "    # 3. Urine pH / Acidic\n",
    "    urine_ph = full_json.get(\"Urine pH\", \"N/A\")\n",
    "    try: \n",
    "        if float(urine_ph) < 6.0:\n",
    "            plans.append(\"✅ ACIDIC URINE DETECTED: Increase plant-based alkaline foods.\")\n",
    "    except: pass\n",
    "\n",
    "    return status, plans\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN EXECUTION (Automated Loading)\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" AUTOMATED AI CLINICAL ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- STEP 1: LOAD JSON DATA ---\n",
    "    if not os.path.exists(JSON_INPUT):\n",
    "        print(f\"❌ Error: '{JSON_INPUT}' not found.\")\n",
    "        print(\"   Please run the extraction script first to generate this file.\")\n",
    "        exit()\n",
    "        \n",
    "    with open(JSON_INPUT, 'r') as f:\n",
    "        patient_data = json.load(f)\n",
    "        \n",
    "    print(f\"Patient Name: {patient_data.get('Patient Name', 'Unknown')}\")\n",
    "    print(f\"Data Source:  {JSON_INPUT}\")\n",
    "    \n",
    "    # --- STEP 2: MAP TO MODEL ---\n",
    "    input_vector, detected_vals = map_patient_data(patient_data)\n",
    "    \n",
    "    # --- STEP 3: PREDICT ---\n",
    "    risk_score = predict_risk(input_vector)\n",
    "    \n",
    "    # --- STEP 4: GENERATE PRESCRIPTION ---\n",
    "    status, prescription = generate_diet(risk_score, detected_vals, patient_data)\n",
    "    \n",
    "    # --- STEP 5: OUTPUT REPORT ---\n",
    "    print(f\"\\n[1] AI RISK PREDICTION\")\n",
    "    print(f\"    Score: {risk_score:.2%} | Status: {status}\")\n",
    "    \n",
    "    print(f\"\\n[2] KEY DRIVERS (Extracted)\")\n",
    "    for k, v in detected_vals.items():\n",
    "        # Only show values that differ from defaults\n",
    "        if v != DEFAULTS.get(k, 0):\n",
    "            print(f\"    - {k}: {v}\")\n",
    "    \n",
    "    print(f\"\\n[3] PERSONALIZED DIET PLAN\")\n",
    "    if not prescription:\n",
    "        print(\"    - Standard Healthy Diet (No specific restrictions detected).\")\n",
    "    else:\n",
    "        for item in prescription:\n",
    "            print(f\"    {item}\")\n",
    "            \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a769634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AI Model & Scaler Loaded.\n",
      "\n",
      "============================================================\n",
      " FINAL CLINICAL DIET RECOMMENDATION\n",
      "============================================================\n",
      "Patient: Unknown\n",
      "Age/Sex: 41 / Male\n",
      "\n",
      "[1] AI RISK ANALYSIS\n",
      "    Mortality Risk Score: 44.03%\n",
      "    Clinical Category:    MODERATE RISK\n",
      "\n",
      "[2] NUTRITION PRESCRIPTION\n",
      "    Protocol: Diabetic Protocol (Low Glycemic Index)\n",
      "    Target Macros: Carbs 35-40% | Protein 25% | Fat 35-40%\n",
      "\n",
      "[3] SPECIFIC RESTRICTIONS\n",
      "    ⚠️ Limit Net Carbs < 45g per meal\n",
      "    ⚠️ Avoid High GI Fruits (Banana, Mango)\n",
      "\n",
      "[4] CLINICAL RATIONALE\n",
      "    ℹ️ HbA1c is 25.0% (Diabetic Range > 6.5%)\n",
      "    ℹ️ Fasting Glucose is 141.0 mg/dL (High)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. Configuration & Defaults\n",
    "# ==========================================\n",
    "JSON_INPUT = \"patient_vitals.json\"\n",
    "MODEL_PATH = r\"C:\\AINutriCare\\Notebooks\\Milestone_2\\LSTM\\attention_lstm.h5\"\n",
    "SCALER_PATH = r\"C:\\AINutriCare\\Data\\Transformed\\X_final.npy\"\n",
    "\n",
    "# The 17 Features the Model was trained on\n",
    "MODEL_FEATURES = [\n",
    "    \"Heart Rate\", \"MAP\", \"Respiratory Rate\", \"Temperature\", \n",
    "    \"Glucose\", \"Creatinine\", \"BUN\", \"Sodium\", \"Potassium\", \"Hemoglobin\", \"WBC\", \"Lactate\",\n",
    "    \"Fluid Balance\", \"Vasopressors\", \"Sedatives\", \"Antibiotics\", \"Insulin\"\n",
    "]\n",
    "\n",
    "# Baseline for missing vitals (Resting/Stable assumption)\n",
    "DEFAULTS = {\n",
    "    'Heart Rate': 75, 'MAP': 90, 'Respiratory Rate': 16, 'Temperature': 98.4,\n",
    "    'Lactate': 1.0, 'Fluid Balance': 0, 'Vasopressors': 0, 'Sedatives': 0, \n",
    "    'Antibiotics': 0, 'Insulin': 0\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. Load Model Resources\n",
    "# ==========================================\n",
    "class SimpleAttention(Layer):\n",
    "    def __init__(self, units=64, **kwargs):\n",
    "        super(SimpleAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    def get_config(self):\n",
    "        config = super(SimpleAttention, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "    def build(self, input_shape):\n",
    "        self.W1 = self.add_weight(name='att_w1', shape=(input_shape[-1], self.units), initializer='glorot_uniform')\n",
    "        self.W2 = self.add_weight(name='att_w2', shape=(self.units, 1), initializer='glorot_uniform')\n",
    "        self.b1 = self.add_weight(name='att_b1', shape=(self.units,), initializer='zeros')\n",
    "        super(SimpleAttention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        h = tf.nn.tanh(tf.matmul(x, self.W1) + self.b1)\n",
    "        e = tf.squeeze(tf.matmul(h, self.W2), -1)\n",
    "        alpha = tf.nn.softmax(e)\n",
    "        context = x * tf.expand_dims(alpha, -1)\n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, alpha\n",
    "\n",
    "try:\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        model = load_model(MODEL_PATH, custom_objects={'SimpleAttention': SimpleAttention})\n",
    "        # Load scaler stats (Mean/Std) to normalize the input\n",
    "        X_ref = np.load(SCALER_PATH)\n",
    "        X_flat = X_ref.reshape(-1, X_ref.shape[2])\n",
    "        means = np.mean(X_flat, axis=0)\n",
    "        stds = np.std(X_flat, axis=0)\n",
    "        stds[stds == 0] = 1.0\n",
    "        print(\"✅ AI Model & Scaler Loaded.\")\n",
    "    else:\n",
    "        print(\"⚠️ Model files not found. Using Rule-Based Logic for Demo.\")\n",
    "        model = None\n",
    "        means = np.zeros(17)\n",
    "        stds = np.ones(17)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 3. Data Mapper (JSON -> AI Vector)\n",
    "# ==========================================\n",
    "def map_json_to_vector(json_data):\n",
    "    \"\"\"\n",
    "    Maps text keys (e.g., 'Fasting Blood Sugar') to Model Features (e.g., 'Glucose').\n",
    "    \"\"\"\n",
    "    def clean(val):\n",
    "        if val in [\"Not Found\", \"N/A\", None]: return None\n",
    "        # Clean string: Remove 'H', 'L', '<', '>', units\n",
    "        s = str(val).replace('H','').replace('L','').replace('<','').replace('>','').strip()\n",
    "        try: return float(s)\n",
    "        except: return None\n",
    "\n",
    "    # Mapping Dictionary\n",
    "    mapping = {\n",
    "        \"Glucose\": \"Fasting Blood Sugar\",\n",
    "        \"Creatinine\": \"Creatinine\",\n",
    "        \"BUN\": \"BUN\",\n",
    "        \"Sodium\": \"Sodium\",\n",
    "        \"Potassium\": \"Potassium\",\n",
    "        \"Hemoglobin\": \"Hemoglobin\",\n",
    "        \"WBC\": \"WBC\"\n",
    "    }\n",
    "\n",
    "    vector = []\n",
    "    extracted_vals = {}\n",
    "\n",
    "    for feature in MODEL_FEATURES:\n",
    "        report_key = mapping.get(feature)\n",
    "        val = clean(json_data.get(report_key))\n",
    "        \n",
    "        # Scaling Fix: WBC in report is often /cmm (10570), Model expects k/uL (10.57)\n",
    "        if feature == \"WBC\" and val and val > 1000:\n",
    "            val = val / 1000.0\n",
    "\n",
    "        if val is not None:\n",
    "            vector.append(val)\n",
    "            extracted_vals[feature] = val\n",
    "        else:\n",
    "            vector.append(DEFAULTS.get(feature, 0))\n",
    "\n",
    "    return np.array(vector), extracted_vals\n",
    "\n",
    "# ==========================================\n",
    "# 4. Diet Prescription Engine\n",
    "# ==========================================\n",
    "def generate_diet_plan(prob, vals, full_data):\n",
    "    plan = {\n",
    "        \"Status\": \"STABLE\",\n",
    "        \"Diet_Type\": \"Standard Balanced Diet\",\n",
    "        \"Macros\": {\"Carbs\": \"50%\", \"Protein\": \"20%\", \"Fat\": \"30%\"},\n",
    "        \"Restrictions\": [],\n",
    "        \"Rationale\": []\n",
    "    }\n",
    "\n",
    "    # --- 1. RISK ASSESSMENT ---\n",
    "    if prob > 0.60:\n",
    "        plan[\"Status\"] = \"HIGH RISK (Metabolic Instability)\"\n",
    "        plan[\"Restrictions\"].append(\"Strict Monitoring Required\")\n",
    "    elif prob > 0.40:\n",
    "        plan[\"Status\"] = \"MODERATE RISK\"\n",
    "\n",
    "    # --- 2. DIABETES LOGIC ---\n",
    "    glucose = vals.get(\"Glucose\", 0)\n",
    "    hba1c_str = full_data.get(\"HbA1c\", \"0\").replace('H','').strip()\n",
    "    try: hba1c = float(hba1c_str)\n",
    "    except: hba1c = 0\n",
    "    \n",
    "    if glucose > 126 or hba1c > 6.5:\n",
    "        plan[\"Diet_Type\"] = \"Diabetic Protocol (Low Glycemic Index)\"\n",
    "        plan[\"Macros\"] = {\"Carbs\": \"35-40%\", \"Protein\": \"25%\", \"Fat\": \"35-40%\"}\n",
    "        plan[\"Restrictions\"].append(\"Limit Net Carbs < 45g per meal\")\n",
    "        plan[\"Restrictions\"].append(\"Avoid High GI Fruits (Banana, Mango)\")\n",
    "        plan[\"Rationale\"].append(f\"HbA1c is {hba1c}% (Diabetic Range > 6.5%)\")\n",
    "        plan[\"Rationale\"].append(f\"Fasting Glucose is {glucose} mg/dL (High)\")\n",
    "\n",
    "    # --- 3. RENAL LOGIC ---\n",
    "    creat = vals.get(\"Creatinine\", 0)\n",
    "    if creat > 1.3:\n",
    "        plan[\"Restrictions\"].append(\"Restrict Potassium (Bananas, Potatoes)\")\n",
    "        plan[\"Restrictions\"].append(\"Limit Protein to 0.8g/kg\")\n",
    "        plan[\"Rationale\"].append(f\"Creatinine elevated ({creat} mg/dL)\")\n",
    "\n",
    "    # --- 4. LIPID LOGIC ---\n",
    "    chol_str = full_data.get(\"Total Cholesterol\", \"0\").replace('H','').strip()\n",
    "    try: chol = float(chol_str)\n",
    "    except: chol = 0\n",
    "    \n",
    "    if chol > 200:\n",
    "        plan[\"Restrictions\"].append(\"Low Saturated Fat (<7% total cal)\")\n",
    "        plan[\"Rationale\"].append(f\"Cholesterol is {chol} mg/dL\")\n",
    "\n",
    "    return plan\n",
    "\n",
    "# ==========================================\n",
    "# 5. Execution Loop\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" FINAL CLINICAL DIET RECOMMENDATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. Load Extracted Data\n",
    "    if not os.path.exists(JSON_INPUT):\n",
    "        print(\"Error: JSON input not found. Run the Extraction script first.\")\n",
    "        exit()\n",
    "        \n",
    "    with open(JSON_INPUT, 'r') as f:\n",
    "        patient_data = json.load(f)\n",
    "\n",
    "    print(f\"Patient: {patient_data.get('Patient Name', 'Unknown')}\")\n",
    "    print(f\"Age/Sex: {patient_data.get('Age', '?')} / {patient_data.get('Gender', '?')}\")\n",
    "\n",
    "    # 2. AI Prediction\n",
    "    input_vec, active_vals = map_json_to_vector(patient_data)\n",
    "    \n",
    "    # Simulate 24h trajectory for the LSTM\n",
    "    trajectory = np.tile(input_vec, (24, 1))\n",
    "    scaled_input = (trajectory - means) / stds\n",
    "    scaled_input = scaled_input.reshape(1, 24, 17)\n",
    "    \n",
    "    if model:\n",
    "        risk_score = model.predict(scaled_input, verbose=0)[0][0]\n",
    "    else:\n",
    "        # Fallback Logic if model missing\n",
    "        gluc = active_vals.get(\"Glucose\", 100)\n",
    "        risk_score = 0.75 if gluc > 140 else 0.25\n",
    "\n",
    "    # 3. Generate Diet\n",
    "    diet = generate_diet_plan(risk_score, active_vals, patient_data)\n",
    "\n",
    "    # 4. Output Report\n",
    "    print(f\"\\n[1] AI RISK ANALYSIS\")\n",
    "    print(f\"    Mortality Risk Score: {risk_score:.2%}\")\n",
    "    print(f\"    Clinical Category:    {diet['Status']}\")\n",
    "    \n",
    "    print(f\"\\n[2] NUTRITION PRESCRIPTION\")\n",
    "    print(f\"    Protocol: {diet['Diet_Type']}\")\n",
    "    print(f\"    Target Macros: Carbs {diet['Macros']['Carbs']} | Protein {diet['Macros']['Protein']} | Fat {diet['Macros']['Fat']}\")\n",
    "    \n",
    "    if diet['Restrictions']:\n",
    "        print(\"\\n[3] SPECIFIC RESTRICTIONS\")\n",
    "        for r in diet['Restrictions']:\n",
    "            print(f\"    ⚠️ {r}\")\n",
    "            \n",
    "    if diet['Rationale']:\n",
    "        print(\"\\n[4] CLINICAL RATIONALE\")\n",
    "        for r in diet['Rationale']:\n",
    "            print(f\"    ℹ️ {r}\")\n",
    "            \n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nutricare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
